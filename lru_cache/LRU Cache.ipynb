{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LRU Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "Node for doubly linked list\n",
    "\"\"\"\n",
    "class Node:\n",
    "    def __init__(self, key, value):\n",
    "        self.key = key     # instance variable to hold the key\n",
    "        self.value = value # instance variable to hold value\n",
    "        self.next = None   # forward pointer for doubly linked list\n",
    "        self.prev = None   # backward pointer for doubly linked list\n",
    "\n",
    "    def get_value(self):\n",
    "        return self.value\n",
    "\n",
    "    def get_key(self):\n",
    "        return self.key\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.key) + ':' + self.value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Doubly linked list to keep track of usage of cache entries\n",
    "Cache entry gets pushed to the front of the doubly linked list as they get created\n",
    "When the entry is accessed it is brought to the front of the linked list \n",
    "unless it is in the front of the queue already\n",
    "At any time element in the front is the most recently accessed entry\n",
    "When cache is filled and a new key needs to be inserted the last element of the doubly linked list is removed\n",
    "as this is the least recently used element\n",
    "\"\"\"\n",
    "class UsageList:\n",
    "    def __init__(self):\n",
    "        self.head = None\n",
    "        self.tail = None\n",
    "\n",
    "    \"\"\"\n",
    "    Insert at the front of the doubly linked list\n",
    "    Parameter: n - element that needs to be inserted to the linked list\n",
    "    Returns the value of the key\n",
    "    \"\"\"\n",
    "    def insert(self, n):\n",
    "        if self.head is None:\n",
    "            # If this is the first node then initialize head and tail pointer to pint to this node\n",
    "            self.head = self.tail = n\n",
    "        else:\n",
    "            # Otherwise only head pointer needs to be manipulated\n",
    "            self.head.prev = n\n",
    "            n.next = self.head\n",
    "            self.head = n\n",
    "        return n.get_value()\n",
    "\n",
    "    \"\"\"\n",
    "    Remove the last element pointed by tail pointer\n",
    "    This element is the one which is least recently used\n",
    "    Returns the key fo the element purged from cache\n",
    "    \"\"\" \n",
    "    def remove(self):\n",
    "        if self.tail is not None:\n",
    "            oldest_key = self.tail.key\n",
    "            self.tail = self.tail.prev\n",
    "            if self.tail is None:\n",
    "                # This was the only element. After removal, doubly linked list is empty\n",
    "                # tail pointer is already set to None\n",
    "                # Do the same for head pointer as well\n",
    "                self.head = self.tail\n",
    "            else:\n",
    "                # Otherwise adjust the next pointer of the element before the one that is removed\n",
    "                # Set the next pointer of this node to none\n",
    "                self.tail.next = None\n",
    "            return oldest_key\n",
    "        else:\n",
    "            # If the doubly linked list is empty then there is nothing to remove\n",
    "            # raise exception in that case\n",
    "            raise Exception(\"Invalid remove operation when list is empty\")\n",
    "\n",
    "    \"\"\"\n",
    "    When an element is accessed this method brings the element to the front of the list\n",
    "    That way we keep track of of aging of the elements\n",
    "    Parameter: n - element that needs to be brought to front of the list\n",
    "    Returns the value of the element which is moved to front\n",
    "    \n",
    "    \"\"\"\n",
    "    def bring_to_front(self, n):\n",
    "        if self.head != n: # This is the front of cache\n",
    "            n.prev.next = n.next\n",
    "            if n.next is not None:\n",
    "                n.next.prev = n.prev\n",
    "            n.prev = None\n",
    "            self.insert(n)\n",
    "        return n.get_value()\n",
    "\n",
    "    \"\"\"\n",
    "    Helper generator utility to traverse the doubly linked list\n",
    "    Parameter:\n",
    "    value: True returns the values in order of recency of use (most recent to least)\n",
    "           False returns the keys in order of recency of use (most recent to least)\n",
    "    \"\"\"\n",
    "    def dump(self, value=True):\n",
    "        ptr = self.head\n",
    "        while ptr is not None:\n",
    "            data = ptr.get_value() if value else ptr.get_key()\n",
    "            ptr = ptr.next\n",
    "            yield data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRU_Cache(object):\n",
    "    def __init__(self, capacity):\n",
    "        self.cache = {}          # Dictionary used to store key and reference to cache entry in doubly linked list\n",
    "        self.capacity = capacity # Max capacity of the cache\n",
    "        self.size = 0            # Current size of the cache\n",
    "        self.usage = UsageList()\n",
    "    def get(self, key):\n",
    "        # Retrieve item from provided key. Return -1 if nonexistent.\n",
    "        n = self.cache.get(key, None)\n",
    "        if n is not None: # Item is used\n",
    "            # Insert accessed key at the front of the list\n",
    "            return self.usage.bring_to_front(n)\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "    def set(self, key, value):\n",
    "        # Set the value if the key is not present in the cache. If the cache is at capacity remove the oldest item.\n",
    "        if self.size < self.capacity:\n",
    "            if self.get(key) == -1:\n",
    "                n = Node(key, value)\n",
    "                self.cache[key] = n\n",
    "                self.usage.insert(n)\n",
    "                self.size += 1\n",
    "            else:\n",
    "                # No action is needed as the instruction states that \"Set the value if the key is not present in the cache\"\n",
    "                # In this case the key is present. So even if `value` is different we don't update to comply with specification\n",
    "                pass\n",
    "        else:\n",
    "            oldest_key = self.usage.remove()\n",
    "            self.cache.pop(oldest_key)\n",
    "            n = Node(key, value)\n",
    "            self.cache[key] = n\n",
    "            self.usage.insert(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import sys\n",
    "\n",
    "\"\"\"\n",
    "Unit testing class for LRU cache\n",
    "\"\"\"\n",
    "\n",
    "class Test_LRU_Cache(unittest.TestCase):\n",
    "    def setup(self, capacity):\n",
    "        return LRU_Cache(capacity)\n",
    "\n",
    "    # Two elements are copied to cache and the second one is accessed\n",
    "    # Cache is not full.\n",
    "    def test_get_element_when_cache_not_full(self):\n",
    "        # Max cache size is 3\n",
    "        lru_cache = self.setup(3)\n",
    "        # Two key & value pairs are put in cache\n",
    "        # Cache is not full till now\n",
    "        for i in [1, 2]:\n",
    "            lru_cache.set(i, \"data-%d\" % i)\n",
    "        self.assertEqual(lru_cache.capacity, 3)\n",
    "        self.assertEqual(lru_cache.size, 2)\n",
    "        data = lru_cache.get(2)\n",
    "        self.assertEqual(data, \"data-2\")\n",
    "\n",
    "    # Cache is empty and attempt to access an element by key should return -1\n",
    "    def test_get_element_when_cache_empty(self):\n",
    "        lru_cache = self.setup(3)\n",
    "        self.assertEqual(lru_cache.capacity, 3)\n",
    "        self.assertEqual(lru_cache.size, 0)\n",
    "        data = lru_cache.get(2)\n",
    "        self.assertEqual(data, -1)\n",
    "\n",
    "    # There elements were moved to cache. After that cache is full\n",
    "    # Attempt to put 4th element will result in LRU element being thrown out\n",
    "    # Accessing 4th element should give back the value associated with 4th element\n",
    "    def test_set_element_when_cache_is_full(self):\n",
    "        # Max cache size is 3\n",
    "        lru_cache = self.setup(3)\n",
    "        # There key & value pairs are put in cache\n",
    "        for i in [1, 2, 3]:\n",
    "            lru_cache.set(i, \"data-%d\" % i)\n",
    "        self.assertEqual(lru_cache.capacity, 3)\n",
    "        self.assertEqual(lru_cache.size, 3)\n",
    "        # Fourth element is written to cache. This will age out one of the elements\n",
    "        # Element (1, \"data-1\") is the least used element. That should get dropped off\n",
    "        lru_cache.set(4, \"data-4\")\n",
    "        data = lru_cache.get(4)\n",
    "        # Cache now should contain following keys [4, 3, 2]\n",
    "        self.assertEqual(data, \"data-4\")\n",
    "        data = lru_cache.get(1)\n",
    "        self.assertEqual(data, -1)\n",
    "        for i in [2, 3, 4]:\n",
    "            data = lru_cache.get(i)\n",
    "            self.assertEqual(data,\"data-%d\" % i)\n",
    "\n",
    "    # There elements were moved to cache. After that cache is full\n",
    "    # Attempt to put 4th element will result in LRU element being thrown out\n",
    "    # Confirm the order of the elements in cache \n",
    "    def test_lru_purged_when_cache_is_full(self):\n",
    "        lru_cache = self.setup(3)\n",
    "        # There key & value pairs are put in cache\n",
    "        for i in [1, 2, 3]:\n",
    "            lru_cache.set(i, \"data-%d\" % i)\n",
    "        lru_cache.get(2)\n",
    "        lru_cache.get(3)\n",
    "        # Least recently used element is with key = 1\n",
    "        lru_cache.set(4, \"data-4\")\n",
    "        # Cache contains elements with following keys in this order [4, 3, 2]\n",
    "        cache_keys = [k for k in lru_cache.usage.dump(value=False)]\n",
    "        self.assertEqual(cache_keys, [4, 3, 2]) \n",
    "        self.assertEqual([k for k in lru_cache.usage.dump()], ['data-4', 'data-3', 'data-2'])\n",
    "        # Element with key = 1 has been purged from cache\n",
    "        self.assertTrue(1 not in cache_keys)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
